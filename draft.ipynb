{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc46cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed26305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LogistRegression(object):\n",
    "#     def __init__(self):\n",
    "#         self.intercept_ = None\n",
    "#         self.coef_ = None\n",
    "#         self.__theta = None\n",
    "#     def __sigmoid(self, t):\n",
    "#         return 1 / (1.+ np.exp(-t))\n",
    "#     def fit(self, X_train, y_train,eta = 0.01, n_iters = 1e4 ):\n",
    "#         def J(theta, X_b, y):\n",
    "#             y_hat = self.__sigmoid(X_b.dot(theta))\n",
    "#             try:\n",
    "#                 return - np.sum(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))/len(X_b)\n",
    "#             except:\n",
    "#                 return float('inf')\n",
    "#         def dJ(theta, X_b, y):\n",
    "#             return X_b.T.dot(self.__sigmoid(X_b.dot(theta)) - y)/len(X_b)\n",
    "\n",
    "#         def gradient_descent(X_b, y, initial_theta, eta, n_iters=1e4, epsilon=1e-8):\n",
    "#             theta = initial_theta\n",
    "#             i_iters = 0\n",
    "#             while i_iters < n_iters:\n",
    "#                 last_theta = theta\n",
    "#                 gradient = dJ(theta, X_b, y)\n",
    "#                 theta = theta - gradient * eta\n",
    "#                 if abs(J(theta, X_b, y) - J(last_theta, X_b, y)) < epsilon:\n",
    "#                     break\n",
    "#                 i_iters += 1\n",
    "#             return theta\n",
    "\n",
    "#         X_b = np.hstack([np.ones((len(X_train), 1)), X_train])\n",
    "#         inital_theta = np.zeros(X_b.shape[1])\n",
    "#         self.__theta = gradient_descent(X_b, y_train, inital_theta, eta, n_iters)\n",
    "#         self.coef_ = self.__theta[1:]\n",
    "#         self.intercept_ = self.__theta[0]\n",
    "#         return self\n",
    "#     def predict_proba(self, X_test):\n",
    "#         X_b = np.hstack([np.ones((len(X_test), 1)), X_test])\n",
    "#         return self.__sigmoid(X_b.dot(self.__theta))\n",
    "#     def predict(self, X_test):\n",
    "#         proba = self.predict_proba(X_test)\n",
    "#         return np.array(proba >=0.5, dtype='int')\n",
    "#     def score(self, X_test, y_test):\n",
    "#         return R_square(y_test, self.predict(X_test))\n",
    "#     def __repr__(self):\n",
    "#         return \"LogisticRegression()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "608132ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, add_bias=True, learning_rate=.1, epsilon=1e-4, max_iters=1e5, verbose=False):\n",
    "        self.add_bias = add_bias\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon = epsilon                        #to get the tolerance for the norm of gradients \n",
    "        self.max_iters = max_iters                    #maximum number of iteration of gradient descent\n",
    "        self.verbose = verbose\n",
    "    def gradient(self, x, y):\n",
    "        logistic = lambda z: 1./ (1 + np.exp(-z))       #logistic function\n",
    "        N,D = x.shape\n",
    "        yh = logistic(np.dot(x, self.w))    # predictions  size N\n",
    "        grad = np.dot(x.T, yh - y)/N        # divide by N because cost is mean over N points\n",
    "        return grad  \n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        logistic = lambda z: 1./ (1 + np.exp(-z))       #logistic function\n",
    "        if x.ndim == 1:\n",
    "            x = x[:, None]\n",
    "        if self.add_bias:\n",
    "            N = x.shape[0]\n",
    "            x = np.column_stack([x,np.ones(N)])\n",
    "        N,D = x.shape\n",
    "        self.w = np.zeros(D)\n",
    "        g = np.inf \n",
    "        t = 0\n",
    "        # the code snippet below is for gradient descent\n",
    "        while np.linalg.norm(g) > self.epsilon and t < self.max_iters:\n",
    "            g = self.gradient(x, y)\n",
    "            self.w = self.w - self.learning_rate * g \n",
    "            t += 1\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f'terminated after {t} iterations, with norm of the gradient equal to {np.linalg.norm(g)}')\n",
    "            print(f'the weight found: {self.w}')\n",
    "        return self\n",
    "    def cost_fn(x, y, w):\n",
    "        N, D = x.shape                                                       \n",
    "        z = np.dot(x, w)\n",
    "        J = np.mean(y * np.log1p(np.exp(-z)) + (1-y) * np.log1p(np.exp(z)))  #log1p calculates log(1+x) to remove floating point inaccuracies \n",
    "        return J\n",
    "    def predict(self, x):\n",
    "        logistic = lambda z: 1./ (1 + np.exp(-z))       #logistic function\n",
    "        if x.ndim == 1:\n",
    "            x = x[:, None]\n",
    "        Nt = x.shape[0]\n",
    "        if self.add_bias:\n",
    "            x = np.column_stack([x,np.ones(Nt)])\n",
    "        yh = logistic(np.dot(x,self.w))            #predict output\n",
    "        \n",
    "        res = np.array(yh >=0.5, dtype='int')\n",
    "        print(res)\n",
    "        return res\n",
    "    def score(self, X_test, y_test):\n",
    "        return R_square(y_test, self.predict(X_test))\n",
    "    def __repr__(self):\n",
    "        return \"LogisticRegression()\"\n",
    "    def accuracy(self, X_test, y_test):\n",
    "        y_hat = self.predict(X_test)\n",
    "       \n",
    "\n",
    "        return sum(y_hat == y_test)/len(y_hat)\n",
    "class StandardScaler(object):\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.scale_ = None\n",
    "    def fit(self, X):\n",
    "        self.mean_ = [np.mean(X[:, i]) for i in range(X.shape[1])]\n",
    "        self.scale_ = [np.std(X[:, i]) for i in range(X.shape[1])]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        resX = np.empty(shape=X.shape, dtype=float)\n",
    "        for col in range(X.shape[1]):\n",
    "            resX[:, col] = (X[:, col] - self.mean_[col])/self.scale_[col]\n",
    "\n",
    "        # k = X_train.shape\n",
    "        # for n in k[1] :\n",
    "        #     X_train[:, n] = (X_train[:, n] - np.mean(X_train[:, n]))/np.std(X_train[:, n])\n",
    "        return resX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "79378764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def accuracy_score(y_hat, y_true):\n",
    "    return sum(y_hat == y_true)/len(y_true)\n",
    "def mean_square_error(y_true, y_predict):\n",
    "    assert  len(y_true) ==len(y_predict)\n",
    "    return np.sum((y_true-y_predict)**2)/len(y_true)\n",
    "def rse(y_true, y_predict):\n",
    "    return np.sqrt(mean_square_error(y_true, y_predict))\n",
    "def mae(y_true, y_predict):\n",
    "    return np.sum(np.abs(y_true - y_predict)) / len(y_true)\n",
    "def R_square(y_true, y_predict):\n",
    "    return 1 - mean_square_error(y_true, y_predict)/np.var(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "14a4bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(self, x, y):\n",
    "        N,D = x.shape\n",
    "        yh = logistic(np.dot(x, self.w))    # predictions  size N\n",
    "        grad = np.dot(x.T, yh - y)/N        # divide by N because cost is mean over N points\n",
    "        return grad  \n",
    "    \n",
    "logistic = lambda z: 1./ (1 + np.exp(-z))       #logistic function\n",
    "def cost_fn(x, y, w):\n",
    "    N, D = x.shape                                                       \n",
    "    z = np.dot(x, w)\n",
    "    J = np.mean(y * np.log1p(np.exp(-z)) + (1-y) * np.log1p(np.exp(z)))  #log1p calculates log(1+x) to remove floating point inaccuracies \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "27bf8955",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./data_A2/diabetes/diabetes_train.csv\")\n",
    "df_test = pd.read_csv(\"./data_A2/diabetes/diabetes_test.csv\")\n",
    "df_val = pd.read_csv(\"./data_A2/diabetes/diabetes_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a7619fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df_train.iloc[:, :-1].to_numpy()\n",
    "train_y = df_train.iloc[:, -1].to_numpy()\n",
    "val_x = df_val.iloc[:, :-1].to_numpy()\n",
    "val_y = df_val.iloc[:, -1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7c6704ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 8)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b4bbf332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = np.ndarray(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e6652dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y = df_train.iloc[:, -1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "39a5c2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 1 1 0 1 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1\n",
      " 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0\n",
      " 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0\n",
      " 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1\n",
      " 0 1 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "74bda77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>144</td>\n",
       "      <td>82</td>\n",
       "      <td>26</td>\n",
       "      <td>285</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.452</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>68</td>\n",
       "      <td>19</td>\n",
       "      <td>180</td>\n",
       "      <td>30.5</td>\n",
       "      <td>1.391</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>156</td>\n",
       "      <td>86</td>\n",
       "      <td>28</td>\n",
       "      <td>155</td>\n",
       "      <td>34.3</td>\n",
       "      <td>1.189</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>82</td>\n",
       "      <td>46</td>\n",
       "      <td>180</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0.335</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>90</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>44.1</td>\n",
       "      <td>0.686</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>4</td>\n",
       "      <td>158</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.803</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>12</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.297</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.805</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>32.2</td>\n",
       "      <td>0.497</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>76</td>\n",
       "      <td>27</td>\n",
       "      <td>207</td>\n",
       "      <td>43.6</td>\n",
       "      <td>1.034</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              5      144             82             26      285  32.0   \n",
       "1              0      128             68             19      180  30.5   \n",
       "2              9      156             86             28      155  34.3   \n",
       "3              1      144             82             46      180  46.1   \n",
       "4              0      179             90             27        0  44.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "595            4      158             78              0        0  32.9   \n",
       "596           12       84             72             31        0  29.7   \n",
       "597            2      158             90              0        0  31.6   \n",
       "598            2       83             66             23       50  32.2   \n",
       "599            5      187             76             27      207  43.6   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.452   58        1  \n",
       "1                       1.391   25        1  \n",
       "2                       1.189   42        1  \n",
       "3                       0.335   46        1  \n",
       "4                       0.686   23        1  \n",
       "..                        ...  ...      ...  \n",
       "595                     0.803   31        1  \n",
       "596                     0.297   46        1  \n",
       "597                     0.805   66        1  \n",
       "598                     0.497   22        0  \n",
       "599                     1.034   53        1  \n",
       "\n",
       "[600 rows x 9 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dd4530be",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9f07cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler.fit(train_x)\n",
    "train_x_std = std_scaler.transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2709dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler.fit(val_x)\n",
    "val_x_std = std_scaler.transform(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed2d43d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c528a92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d884ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(learning_rate=1e-3, verbose=True, epsilon=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1969d0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated after 100000 iterations, with norm of the gradient equal to 9.388086494019812e-05\n",
      "the weight found: [ 0.490168    1.17023562 -0.22574154 -0.05961615 -0.05721845  0.69279054\n",
      "  0.30081972  0.12838712 -0.84671712]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(train_x_std, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ba0177d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1\n",
      " 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "p = lr_clf.predict(val_x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9372c7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b1e9e2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.8571428571428577"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a1446b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0\n",
      " 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
      "35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.accuracy(val_x, val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5b6a7090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "46469760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6e66b818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p==val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b56bab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3606fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
